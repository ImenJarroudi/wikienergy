{
 "metadata": {
  "name": "",
  "signature": "sha256:449768e3c38ae1d2270dd872f9f50db45fa1ff0e63215abf98a75c7d6372df92"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#air=0,2\n",
      "#fridge=0,.12\n",
      "#install sqlalchemy,pymongo,scikit-learn,update pandas\n",
      "import sys\n",
      "sys.path.append('../../') # or non-Unix equivalent (add wikienergy/ to path)\n",
      "import numpy as np\n",
      "import pickle\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from disaggregator import PecanStreetDatasetAdapter as psda\n",
      "from disaggregator import utils\n",
      "from disaggregator import fhmm\n",
      "from disaggregator import evaluation_metrics as metric\n",
      "from disaggregator import appliance as app\n",
      "from sklearn import hmm\n",
      "from copy import deepcopy\n",
      "import pymc\n",
      "import pylab\n",
      "\n",
      "import json\n",
      "import urllib2\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import collections \n",
      "import matplotlib.pyplot as plt\n",
      "from scipy import stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_FHMM_single_type(types_eval,temps_eval,best_models,device_type_name,thresh,min_val=0,mass=True,plot_sum=True,plot_ind=False):\n",
      "    model_eval_dict={}\n",
      "    test_data={}\n",
      "    model_eval_dict['precision']=[]\n",
      "    model_eval_dict['recall']=[]\n",
      "    model_eval_dict['test_energy']=[]\n",
      "    model_eval_dict['pred_energy']=[]\n",
      "    model_eval_dict['error_perc']=[]\n",
      "    model_eval_dict['power_total_sums']=[]\n",
      "    model_eval_dict['diff_power_perc']=[]\n",
      "    model_eval_dict['good_house_ids']=[]\n",
      "    model_eval_dict['bad_house_ids']=[]\n",
      "    model_eval_dict['power_avg_good']=0\n",
      "    model_eval_dict['power_avg_bad']=0\n",
      "    model_eval_dict['num_less_than']=0\n",
      "    model_eval_dict['num_less_than_more_min']=0\n",
      "    model_eval_dict['num_more_min']=0\n",
      "    model_eval_dict['num_less_than_less_min']=0\n",
      "    model_eval_dict['num_less_min']=0\n",
      "    for house_num,instance_test in enumerate(types_eval[device_type_name].instances):\n",
      "        model_eval_dict=eval_model_with_instance(types_eval,temps_eval,device_type_name,best_models,house_num,model_eval_dict,thresh,min_val,mass,plot_ind)\n",
      "    for house_num,instance_test in enumerate(types_eval[device_type_name].instances):\n",
      "        for trace_num,trace in enumerate(types_eval[device_type_name].instances[house_num].traces):\n",
      "            test_data[device_type_name]=utils.trace_series_to_numpy_array(types_eval[device_type_name].instances[house_num].traces[trace_num].series)\n",
      "            model_eval_dict['baseline_perc']=(model_eval_dict['test_energy']-(np.sum(model_eval_dict['test_energy'])/len(model_eval_dict['test_energy'])))\n",
      "            model_eval_dict['baseline_less_than']=sum(abs(i) < thresh for i in model_eval_dict['baseline_perc'])\n",
      "            model_eval_dict['baseline_less_than_perc']=model_eval_dict['baseline_less_than']/float(len(model_eval_dict['baseline_perc']))*100\n",
      "            model_eval_dict['num_less_than_perc']=model_eval_dict['num_less_than']/float(len(model_eval_dict['error_perc']))*100\n",
      "            if(model_eval_dict['num_more_min']>0):\n",
      "                model_eval_dict['num_less_than_more_min_perc']=model_eval_dict['num_less_than_more_min']/float(model_eval_dict['num_more_min'])*100\n",
      "            else:\n",
      "                 model_eval_dict['num_less_than_more_min_perc']=0\n",
      "            if(model_eval_dict['num_less_min']>0):\n",
      "                model_eval_dict['num_less_than_less_min_perc']=model_eval_dict['num_less_than_less_min']/float(model_eval_dict['num_less_min'])*100\n",
      "            else:\n",
      "                 model_eval_dict['num_less_than_less_min_perc']=0\n",
      "    if(plot_sum):\n",
      "        plot_and_sum_model_eval(model_eval_dict)\n",
      "    return model_eval_dict\n",
      "\n",
      "def eval_model_with_instance(types_eval,temps_eval,device_type_name,best_models,house_num,model_eval_dict,thresh,min_val=0,mass=True,plot=False):\n",
      "    model_fhmm,means_fhmm,var_fhmm=fhmm.generate_FHMM_from_HMMs(best_models)\n",
      "    appliance_list=['air1','not_air']\n",
      "    for trace_num,trace in enumerate(types_eval[device_type_name].instances[house_num].traces):\n",
      "        test_data[device_type_name]=utils.trace_series_to_numpy_array(types_eval[device_type_name].instances[house_num].traces[trace_num].series)\n",
      "        power_total=utils.trace_series_to_numpy_array(types_eval['use'].instances[house_num].traces[trace_num].series)\n",
      "        [decoded_states, decoded_power]=fhmm.predict_with_FHMM(model_fhmm,means_fhmm,var_fhmm,power_total)\n",
      "        if(plot):\n",
      "            plt.figure()\n",
      "            plt.plot(power_total)\n",
      "            plt.plot(test_data['air1'])\n",
      "            plt.plot(decoded_power['air1'],'r')\n",
      "        truth_states=metric.guess_truth_from_power(test_data[device_type_name],2)\n",
      "        eval_metrics=metric.get_positive_negative_stats(truth_states,decoded_states[device_type_name])\n",
      "        diff_power_perc=(metric.sum_error(test_data[device_type_name],decoded_power[device_type_name])*100/np.sum(test_data[device_type_name]))  \n",
      "        precision_val=(metric.get_precision(eval_metrics['tp'],eval_metrics['fp']))\n",
      "        recall_val=(metric.get_sensitivity(eval_metrics['tp'],eval_metrics['fn']))\n",
      "        model_eval_dict['precision'].append(precision_val)\n",
      "        model_eval_dict['recall'].append(recall_val)\n",
      "        test_energy=(np.sum(test_data[device_type_name])/len(test_data[device_type_name]))*24*30\n",
      "        pred_energy=(np.sum(decoded_power[device_type_name])/len(decoded_power[device_type_name]))*24*30\n",
      "        error_perc=float(test_energy-pred_energy)/test_energy*100\n",
      "        power_total_sum=np.sum(power_total/len(power_total)*24*30)\n",
      "        model_eval_dict['diff_power_perc'].append(diff_power_perc)\n",
      "        model_eval_dict['test_energy'].append(test_energy)\n",
      "        model_eval_dict['pred_energy'].append(pred_energy)\n",
      "        model_eval_dict['error_perc'].append(error_perc)\n",
      "        model_eval_dict['power_total_sums'].append(power_total_sum)\n",
      "        if(power_total_sum>min_val):\n",
      "            model_eval_dict['num_more_min']=model_eval_dict['num_more_min']+1\n",
      "        else:\n",
      "            model_eval_dict['num_less_min']=model_eval_dict['num_less_min']+1\n",
      "        if(abs(error_perc)<thresh):\n",
      "            model_eval_dict['num_less_than']=model_eval_dict['num_less_than']+1\n",
      "            model_eval_dict['power_avg_good']=model_eval_dict['power_avg_good']+power_total_sum\n",
      "            model_eval_dict['good_house_ids'].append([trace.metadata['dataid'],house_num,trace_num])\n",
      "            if(power_total_sum>min_val):\n",
      "                model_eval_dict['num_less_than_more_min']= model_eval_dict['num_less_than_more_min']+1\n",
      "            else:\n",
      "                model_eval_dict['num_less_than_less_min']= model_eval_dict['num_less_than_less_min']+1\n",
      "        else:\n",
      "            model_eval_dict['power_avg_bad']=model_eval_dict['power_avg_bad']+power_total_sum\n",
      "            model_eval_dict['bad_house_ids'].append([trace.metadata['dataid'],house_num,trace_num])\n",
      "    return model_eval_dict\n",
      "\n",
      "def plot_and_sum_model_eval(model_eval_dict):\n",
      "    if(model_eval_dict['num_less_than']>0):\n",
      "        print 'Average Power of Houses w/ <'+str(thresh)+'% Error: ' + str(model_eval_dict['power_avg_good']/float(model_eval_dict['num_less_than']))\n",
      "    if((len(model_eval_dict['error_perc'])-model_eval_dict['num_less_than'])>0):\n",
      "        print 'Average Power of Houses w/ >='+str(thresh)+'% Error: '+str(model_eval_dict['power_avg_bad']/float(len(model_eval_dict['error_perc'])-model_eval_dict['num_less_than']))\n",
      "    print\n",
      "    print 'Percentage of Houses with <'+str(thresh)+'% Error (Model):    ' + str(model_eval_dict['num_less_than_perc'])\n",
      "    print 'Percentage of Houses with <'+str(thresh)+'% Error (Baseline): ' + str(model_eval_dict['baseline_less_than_perc'])\n",
      "    print\n",
      "    print 'Percentage of Houses with <'+str(thresh)+'% Error and more than min_val (Model):    ' + str(model_eval_dict['num_less_than_more_min_perc'])\n",
      "    print 'Percentage of Houses with <'+str(thresh)+'% Error and less than min_val (Model):    ' + str(model_eval_dict['num_less_than_less_min_perc'])\n",
      "\n",
      "    \n",
      "    baseline_val=np.sum(model_eval_dict['test_energy'])/len(model_eval_dict['test_energy'])\n",
      "    a=np.empty(len(model_eval_dict['test_energy']))\n",
      "    a[:]=(baseline_val)\n",
      "    base_diff_power_perc=(metric.sum_error(test_data[device_type_name],a)*100/np.sum(test_data[device_type_name]))           \n",
      "    plt.figure()\n",
      "    plt.plot(model_eval_dict['test_energy'],'b')\n",
      "    plt.plot(model_eval_dict['pred_energy'],'r')\n",
      "\n",
      "    plt.plot(a,'k')\n",
      "    plt.title('Predicted Energy (Red), Actual Energy (Blue)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Resamples the data\n",
      "def resample_and_split(devices_types_unsampled_test,sample_rate,length,sample,split):\n",
      "    devices_types_test={}\n",
      "    devices_types_unsplit_test={}\n",
      "    for key in devices_types_unsampled_test:\n",
      "        if(sample):\n",
      "            devices_types_unsplit_test[key]=devices_types_unsampled_test[key].resample(sample_rate)\n",
      "        else:\n",
      "            devices_types_unsplit_test[key]=devices_types_unsampled_test[key]\n",
      "        if(split):\n",
      "            devices_types_test[key]=devices_types_unsplit_test[key].split_by(length)\n",
      "        else:\n",
      "            devices_types_test[key]=devices_types_unsplit_test[key]\n",
      "        print \"Resampled \" + str(key)\n",
      "    return devices_types_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime, timedelta, date\n",
      "#this function returns a json object\n",
      "#Pass in the city, state, and desired date as strings, the date format is YYYYMMDD\n",
      "def get_weather_data(api,city,state,start_date,end_date):  \n",
      "    if(start_date is not None and end_date is not None):\n",
      "\n",
      "        #format our date structure to pass to our http request\n",
      "        date_format = \"%Y%m%d\"\n",
      "        a = datetime.strptime(start_date, date_format)\n",
      "        b = datetime.strptime(end_date, date_format)\n",
      "        #get number of days from start_date to end_date\n",
      "        delta = b - a\n",
      "        num_days = delta.days\n",
      "        objects_list = []\n",
      "    \n",
      "        #create new variable that will create query's for the api\n",
      "        for year in range(0,num_days + 1):\n",
      "            #count from start_date to end_date\n",
      "            dates = a + timedelta(days=year)\n",
      "            #format our str with our date_format\n",
      "            formatted_dates = datetime.strftime(dates, date_format)\n",
      "            #create query which will iterate through desired weather period\n",
      "            query = 'http://api.wunderground.com/api/'+ api +'/history_'+formatted_dates+'/q/'+state+'/'+city+'.json'\n",
      "            #iterate through the number of days and query the api. dump json results every time \n",
      "            f = urllib2.urlopen(query)\n",
      "            #read query as a json string\n",
      "            json_string = f.read()\n",
      "            #parse/load json string\n",
      "            parsed_json = json.loads(json_string)\n",
      "            #Iterate through each json object and append it to an ordered dictionary\n",
      "            for i in parsed_json['history']['observations']:        \n",
      "                d = collections.OrderedDict()\n",
      "                d['date'] = i['date']['mon'] + '/' + i['date']['mday'] + '/' + i['date']['year']\n",
      "                d['time'] = i['date']['pretty'][0:8]\n",
      "                d['temp'] = i['tempi']\n",
      "                d['conds'] = i['conds']\n",
      "                d['wdire'] = i['wdire']\n",
      "                d['wdird'] = i['wdird']\n",
      "                d['hail'] = i['hail']\n",
      "                d['thunder'] = i['thunder']\n",
      "                d['pressurei'] = i['pressurei']\n",
      "                d['snow'] = i['snow']\n",
      "                d['pressurem'] = i['pressurem']\n",
      "                d['fog'] = i['fog']\n",
      "                d['tornado'] = i['tornado']\n",
      "                d['hum'] = i['hum']\n",
      "                d['tempi'] = i['tempi']\n",
      "                d['tempm'] = i['tempm']\n",
      "                d['dewptm'] = i['dewptm']\n",
      "                d['dewpti'] = i['dewpti']\n",
      "                d['rain'] = i['rain']\n",
      "                d['visim'] = i['visi']\n",
      "                d['wspdi'] = i['wspdi']\n",
      "                d['wspdm'] = i['wspdm']\n",
      "                objects_list.append(d)\n",
      "                #dump the dictionary into a json object\n",
      "                j = json.dumps(objects_list)\n",
      "        #append our json object to a list for every day and return its data\n",
      "    #    print j\n",
      "        return j\n",
      "    #If we just need the data for ONE day (pass None for end_date):\n",
      "    if(end_date is None):\n",
      "        f = urllib2.urlopen('http://api.wunderground.com/api/API_KEY/history_'+start_date+'/q/'+state+'/'+city+'.json')\n",
      "        json_string = f.read()\n",
      "        parsed_json = json.loads(json_string)\n",
      "    \n",
      "        objects_list = []\n",
      "        for i in parsed_json['history']['observations']:        \n",
      "            d = collections.OrderedDict()\n",
      "            d['date'] = i['date']['mon'] + '/' + i['date']['mday'] + '/' + i['date']['year']\n",
      "            d['time'] = i['date']['pretty'][0:8]\n",
      "            d['temp'] = i['tempi']\n",
      "            d['conds'] = i['conds']\n",
      "            d['wdire'] = i['wdire']\n",
      "            d['wdird'] = i['wdird']\n",
      "            d['hail'] = i['hail']\n",
      "            d['thunder'] = i['thunder']\n",
      "            d['pressurei'] = i['pressurei']\n",
      "            d['snow'] = i['snow']\n",
      "            d['pressurem'] = i['pressurem']\n",
      "            d['fog'] = i['fog']\n",
      "            d['tornado'] = i['tornado']\n",
      "            d['hum'] = i['hum']\n",
      "            d['tempi'] = i['tempi']\n",
      "            d['tempm'] = i['tempm']\n",
      "            d['dewptm'] = i['dewptm']\n",
      "            d['dewpti'] = i['dewpti']\n",
      "            d['rain'] = i['rain']\n",
      "            d['visim'] = i['visi']\n",
      "            d['wspdi'] = i['wspdi']\n",
      "            d['wspdm'] = i['wspdm']\n",
      "            objects_list.append(d)\n",
      "        \n",
      "        j = json.dumps(objects_list)\n",
      "        return j"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query_results = get_weather_data('API_KEY','78739','TX', '20140401', '20140430')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "may = pd.read_json(query_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for i,date in enumerate(may['date']):\n",
      "    time_array=may['time'][i].split(':')\n",
      "    hour=time_array[0]\n",
      "    mins=time_array[1].split(' ')[0]\n",
      "    may['date'][i]=date.replace(hour=int(hour),minute=int(mins))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "may['time'] = pd.to_datetime(may['date'],utc=True)\n",
      "may.set_index('time', inplace=True)\n",
      "may.index.snap() # snap to nearest frequency"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 230,
       "text": [
        "<class 'pandas.tseries.index.DatetimeIndex'>\n",
        "[2014-04-01 12:11:00, ..., 2014-04-30 11:51:00]\n",
        "Length: 935, Freq: S, Timezone: None"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temps=may['temp']\n",
      "temps_resampled=temps.resample('15T',fill_method='bfill')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load Datasets\n",
      "devices_types_unsampled={}\n",
      "ids_for_devices={}\n",
      "db_url='postgresql://USERNAME:PASSWORD@db.wiki-energy.org:5432/postgres'\n",
      "psda.set_url(db_url)\n",
      "schema = 'shared'\n",
      "tables= psda.get_table_names(schema)\n",
      "print tables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'validated_01_2014', u'validated_02_2014', u'validated_04_2014', u'validated_05_2014', u'validated_03_2014']\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table=tables[2]\n",
      "print table\n",
      "ids_device_name='air1'\n",
      "ids_for_devices[ids_device_name]=psda.get_dataids_with_real_values(schema,table,ids_device_name)\n",
      "print ids_for_devices[ids_device_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "validated_04_2014\n",
        "[26, 59, 86, 93, 94, 280, 410, 434, 484, 499, 580, 624, 661, 739, 744, 774, 821, 871, 936, 1086, 1167, 1283, 1334, 1450, 1507, 1617, 1632, 1681, 1696, 1714, 1718, 1782, 1790, 1830, 1953, 1994, 2034, 2094, 2129, 2156, 2158, 2171, 2242, 2365, 2378, 2470, 2575, 2606, 2638, 2641, 2769, 2787, 2814, 2829, 2845, 2864, 2945, 2953, 2974, 3044, 3092, 3134, 3192, 3221, 3263, 3367, 3394, 3456, 3482, 3504, 3531, 3649, 3652, 3723, 3736, 3778, 3795, 3893, 4135, 4154, 4298, 4313, 4352, 4373, 4505, 4526, 4641, 4767, 4874, 4922, 4956, 4957, 4998, 5026, 5109, 5209, 5218, 5275, 5357, 5395, 5545, 5568, 5677, 5785, 5814, 5852, 5874, 5889, 5938, 5949, 5972, 6139, 6165, 6412, 6636, 6673, 6730, 6826, 6836, 6910, 6941, 7062, 7319, 7390, 7531, 7536, 7617, 7731, 7769, 7788, 7800, 7850, 7863, 7875, 7940, 7951, 8046, 8061, 8079, 8084, 8142, 8188, 8197, 8201, 8292, 8342, 8419, 8645, 8669, 8741, 8956, 9019, 9036, 9121, 9141, 9160, 9343, 9356, 9484, 9488, 9499, 9555, 9578, 9609, 9613, 9643, 9654, 9701, 9729, 9737, 9771, 9830, 9875, 9915, 9922, 9926, 9932, 9934, 9938, 9939, 9982, 9983]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_houses=3\n",
      "device_name='air1'\n",
      "devices_types_unsampled[device_name]=psda.generate_type_for_appliance_by_dataids(schema,table,device_name,ids_for_devices[ids_device_name][10:10+num_houses])\n",
      "device_name='use'\n",
      "devices_types_unsampled[device_name]=psda.generate_type_for_appliance_by_dataids(schema,table,device_name,ids_for_devices[ids_device_name][10:10+num_houses])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "select air1,localminute from \"PecanStreet_SharedData\".validated_04_2014 where dataid=580\n",
        "select air1,localminute from \"PecanStreet_SharedData\".validated_04_2014 where dataid=624"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "select air1,localminute from \"PecanStreet_SharedData\".validated_04_2014 where dataid=661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "select use,localminute from \"PecanStreet_SharedData\".validated_04_2014 where dataid=580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "select use,localminute from \"PecanStreet_SharedData\".validated_04_2014 where dataid=624"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "select use,localminute from \"PecanStreet_SharedData\".validated_04_2014 where dataid=661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devices_types=resample_and_split(devices_types_unsampled,'15T','D',True,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resampled air1\n",
        "Resampled use"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "both=pd.DataFrame(dict(temp = temps_resampled, power = devices_types['use'].instances[house_num].traces[trace_num].series)).dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "power_total=utils.trace_series_to_numpy_array(both['power'])\n",
      "temp_total=utils.trace_series_to_numpy_array(both['temp'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slope,intercept,r_value,p_value,std_error=stats.linregress(power_total.T[0],temp_total.T[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index out of bounds",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-223-df743869a813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinregress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpower_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
       ]
      }
     ],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y=slope*(.7)+intercept\n",
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "77.0051040141\n"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y=(65-intercept)/slope\n",
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-164.460977267\n"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(power_total.T[0],power_total.T[0]*slope+intercept)\n",
      "plt.plot(power_total.T[0],'c')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index out of bounds",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-232-fca0b31bc3b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpower_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpower_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mslope\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpower_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}